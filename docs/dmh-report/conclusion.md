---
authors:
  - Christopher Burr
  - Rosamund Powell
---
# Conclusion

## Co-Creating a Culture of Trust

![An illustration of a user operating a smartphone where a stream of data disappears into a maze](../assets/images/data-maze.png)

> Uncertainty breeds distrust.

When the consequences of potential actions are not easy to identify or evaluate, inaction or inertia can follow. And, such uncertainty and deliberative inertia are only exacerbated in the context of mental health (e.g. challenges that are faced by those with depression or anxiety disorders, such as catastrophising, when attempting to evaluate actions).

In the context of digital mental health technology, vague privacy policies, poorly-specified objectives, pervasive and invasive data extraction, and dubious claims about user safety and clinical efficiency of services, are all sources of uncertainty.

This report has laid out a methodological proposal for how we can begin to address the current culture of distrust that casts a shadow over the digital mental healthcare industry. While we believe that the methodology and recommendations will support this goal, and have presented tentative evidence to justify this belief, the development of a trustworthy ecosystem of digital mental healthcare requires a more collaborative effort.

Therefore, in addition to our methodological proposal of trustworthy assurance and the initial argument patterns, we have also made a series of supporting recommendations (summarised in Table 5.1 for convenience). But what comes next?

*Table 5.1*: a summary of the recommendations made throughout the report.

| Recommendation | Domain |
| --- | --- |
| Insert recommendation | Higher Education |

## Next Steps

In addition to the individual recommendations above this report can also be viewed as a general recommendation itselfâ€”one that calls for the more widespread adoption of the trustworthy assurance methodology. We can even formulate this recommendation as an argument in a pseudo assurance case:

- [Goal]: The widespread adoption of the trustworthy assurance method could develop a more responsible and trustworthy ecosystem of digital mental health technology.
    - [Claim 1] Trustworthy assurance provides a structured method for responsible project governance through internal reflection and participatory engagement.
        - [Evidence 1.1] The project lifecycle model scaffolds reflective and deliberative activities, providing a shared structure for project teams.
        - [Evidence 1.2] Goal, property claims, and evidence elements have a clear relational structure, and can help teams identify gaps in an argument (e.g. claims with missing evidence to help teams identify necessary actions)
    - [Claim 2] Trustworthy assurance depends on participatory processese that facilitate the diverse inclusion of diverse stakeholder perspectives
        - [Evidence 2.1] Stakeholder engagement can support the co-creation of generalisable patterns, as seen in this report
        - [Evidence 2.2] Stakeholder engagement can help anticipate potential risks and adverse impacts that a project team may not have otherwise identified
    - [Claim 3] Trustworthy assurance facilitates accountability and transparent communication between developers and affected stakeholders
        - [Evidence 3.1] Building an assurance case is a process of documentation (or, reporting), and the result can be shared with stakeholders who can verify the accuracy and sufficiency of the case.
        - [Evidence 3.2] Robust and well-validated standards can be used to help teams identify appropriate or permissible forms of evidence (e.g. the health app quality labels proposed in [ISO/TS 82304-2:2021](https://www.iso.org/standard/78182.html).

Ultimately, the veracity of this goal depends on how and whether the methodology is adopted. This report is not a user guide, however, so more work needs to be done to ensure the adoption by organisations is made as straightforward as possible. 

A key next step for our team will be to develop user guidance that can help with this objective. This has already been started, and we currently have a) a full-length article that goes into further detail about the methodology[^ea-article], in relation to ethical principles, and b) a prototype platform that can enable the production of assurance cases[^gh-repo]. However, these proposals have hitherto not connected directly with the more formal work undertaken by those working in safety assurance. This is primarily because we endeavoured to make the trustworthy assurance methodology simple and accessible for the purpose of stakeholder engagement. However, its adoption by developers and engineers would likely benefit from closer integration with standardisation efforts, such as the Goal Structuring Notation (GSN) and the [GSN Standard Working Group](https://scsc.uk/gsn).

[^ea-article]: Burr, C., and Leslie, D. (2022). Ethical assurance: a practical approach to the responsible design, development, and deployment of data-driven technologies. AI Ethics. [https://doi.org/10.1007/s43681-022-00178-0](https://doi.org/10.1007/s43681-022-00178-0)

[^gh-repo]: details of the platform and the code is available through the following GitHub repository, and we welcome contributions to its ongoing development from any open-source developers: [https://github.com/alan-turing-institute/AssurancePlatform](https://github.com/alan-turing-institute/AssurancePlatform)

These efforts will need to remain receptive to ongoing developments in this domain, whether technological (e.g. development of new computational techniques or devices), legislative (e.g. reforms to UK legislation such as the Draft Mental Health Bill, 2022), regulatory (e.g. formation of the [Multi Agency Advice Service](https://transform.england.nhs.uk/ai-lab/ai-lab-programmes/regulating-the-ai-ecosystem/the-multi-agency-advice-service-maas/); proposal of the [Digital Technology Assessment Criteria (DTAC)](https://transform.england.nhs.uk/key-tools-and-info/digital-technology-assessment-criteria-dtac/), or societal (e.g. changing perceptions or attitudes of users towards mental health and well-being services, including data-driven technologies). We hope that the proposal and recommendations set out in this report offers some clarity, structure, and positive direction to help navigate this complex (and multitudinous) space.

![An illustration of two people navigating a path that represents multiple decisions about how to develop a responsible digital society](../assets/images/responsible-innovation.jpg)
