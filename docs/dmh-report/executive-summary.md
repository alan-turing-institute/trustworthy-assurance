---
authors:
  - Christopher Burr
  - Rosamund Powell
tags:
  - executive summary
  - findings
  - recommendations
  - digital-mental-healthcare
---

# Executive Summary

> Trustworthy Assurance is a framework and methodology that can support the design, development, and deployment of data-driven technologies and also create a more responsible and trustworthy ecosystem of digital mental healthcare. 
> 
> The current landscape of digital mental health is characterised by significant uncertainty, a lack of transparency or accountability, and a rising demand that outpaces trusted services and resources. This contributes to a culture of distrust, which may prevent vulnerable users from accessing support. 
> 
> We conducted a series of participatory stakeholder engagement events (e.g. workshops and interviews) to a) identify and explore relevant ethical objectives for digital mental health technologies, such as fairness and explainabilty, b) evaluate and co-design the trustworthy assurance framework and methodology, and c) solicit feedback on the possible reasons for distrust in digital mental health. ...

## Report Overview

Our report is structured as follows:

* [Chapter 1](chapter-1.md) (Introduction): this chapter establishes the background context and conceptual foundations for the report, while also outlining the many challenges that exist for researchers, developers, and policy-makers/regulators working in the domain of digital mental healthcare.
* [Chapter 2](chapter-2.md) (Trustworthy Assurance—Proposing a Framework and Methodology): this chapter introduces the framework and methodology of 'Trustworthy Assurance'. The framework includes a model of a typical project lifecycle for a data-driven technology, and a discussion of several ethical principles, known as the SAFE-D principles. The framework serves as a guide to our methodology for developing an assurance case that promotes trustworthy goals associated with digital mental health technologies. Finally, this chapter also includes an important discussion about 'argument patterns', which support the material presented in [Chapter 5](chapter-5.md).
* [Chapter 3](chapter-3.md): this chapter presents findings from a research sub-project conducted with students and administrators from UK Universities. These engagement events explored the application of trustworthy assurance to the procurement of digital mental health technologies for use in the higher education (HE) sector, as well as general attitudes and perceptions towards the use of data-driven technologies in higher education. A series of recommendations accompany our thematic analysis.
* [Chapter 4](chapter-4.md): this chapter broadens the scope from the previous chapter to present research findings from a series of stakeholder engagement events carried out with regulators and policy-makers, developers, researchers, and users with lived experience of digital mental health technologies. As with the previous chapter, a set of recommendations accompanies our thematic analysis.
* [Chapter 5](chapter-5.md) (Argument Patterns—Fairness and Explainability): in the final main chapter of our report, we introduce, motivate, and explain two argument patterns that are intended to help project teams meet objectives for fair and explainable digital mental health technologies. This chapter also connects the argument patterns to existing and relevant legislation and regulation (e.g. Equality Act 2010).

### Findings and Recommendations

...

<!--recommendations in chapters 3 and 4 are contextual-->

### About the Report

The following summarises what this report is and what it is not:

✅ An introduction to 'Trustworthy Assurance'—a framework and methodology for enabling a more trustworthy ecosystem of digital mental healthcare through the responsible and ethical design, development, and deployment of digital technologies. 
✅ A summary of findings from research conducted on the application of trustworthy assurance to the procurement of digital mental health technologies for use in the higher education (HE) sector. 
✅ A summary of findings from a series of more general stakeholder engagements, exploring the ethics of digital mental healthcare and attitudes towards trustworthy and untrustworthy technologies. 
✅ An explanation and discussion of two argument patterns exploring the goals of fairness and explainability in the design, development, and deployment of digital mental health technologies. 
✅ A series of recommendations, targeted at different stakeholders, for how to enable a more responsible and trustworthy ecosystem of digital mental healthcare.

❌ A comprehensive user guide for 'Trustworthy Assurance' or argument-based assurance—though links and further resources are provided.[^online] 
❌ A critical examination of argument-based assurance.[^critical] 
❌ Findings from a sociological study or series of generalisable results from experiments. 
❌ A review of the current legislative or regulatory publications that are relevant to digital mental healthcare. 
❌ A report with a strong international or multi-national focus. While we make reference to non-UK developments in this domain, our primary focus is on the UK. However, the methodology we present and many of the findings we discuss have value beyond the UK.

[^online]: Work is underway to develop an user guide, and this will be added to the online version of our report when ready. The guide will also include instructions on how to use our tool for producing assurance cases. [^critical]: The following documents provide a more critical examination for those interested: [(Sujan and Habli, 2021)](https://qualitysafety.bmj.com/content/30/12/1047.abstract); [(Burr and Leslie, 2022)](https://link.springer.com/article/10.1007/s43681-022-00178-0).

### Who is this report for?

This report is primarily targeted at the following groups:

* Policy-makers and regulators: *how is the report relevant to this group?*
  * ![](../assets/icons/noun-control-4757893.svg)
* Senior decision-makers: *how is the report relevant to this group?*
  * ![](../assets/icons/noun-regulation-2814477.svg)
* Developers (and product managers) of digital mental health technologies: *how is the report relevant to this group?*
  * ![](../assets/icons/noun-coding-5121824.svg)
* Researchers: *how is the report relevant to this group?*
  * ![](../assets/icons/noun-research-3509304.png)

Users of digital mental health technologies may also find value in the report, but it has not been produced with members of the public as primary target audience. In general, the responsibility for utilising the methodology and implementing and acting upon the recommendations is for the groups above; they are not the responsibility of the user!

### Possible Key Messages and Findings

<!-- Add suggestions here -->

<!--Chapter 3-->

\-        University teams must reflect on duty of care as a legal and ethical goal

\-        Policymakers and government departments must provide clarify on the relative responsibilities of the NHS and university teams to procure digital mental health technologies

\-        Greater attention must also be paid within universities to assigning responsibility for digital mental health technology procurement

\-        Meaningful student evolvement is needed from the outset so student groups can contribute to establishing the overarching goals of student mental health decisions

\-        Universities must work together to leverage collective influence on developers such that developers provide them with more detailed information on the ethical implications of new technologies. Networks such as AMOSSHE, the UK’s Student Services Organisation, can play an important role in stepping forward to provide evidence-based guidance on these topics.

⁃       In an environment where resources are constrained, careful consideration is needed over whether the decision to procure a technology is justified. Where resources are limited, justification of expenditure must go beyond claims that digital services do not replace in-person support to make transparent where funds come from and why the benefits of a digital service are seen to outweigh other options.

⁃       Greater integration with research departments is needed to ensure evidence is available on who is best served by specific mental health services. Universities can draw on their own research resources in order to take a deeper look at who is and is not benefiting from digital interventions

⁃       Resource allocation within student services should take account of issues such as digital poverty, especially in light of the rise in remote learning following the pandemic.

⁃       A balance must be struck between empowering students to make their own choices without placing the burden of responsibility for mental health on them.

\-        To ensure students are aware of the services available, communications should be delivered by as many stakeholders as possible to include academic staff, student unions and student societies. University mental health teams should be careful to communicate honestly with students about both benefits and risks of technologies, including transparency communications about efficacy and data sharing.

\-        While in-depth and legally binding privacy policies are essential, an accessible breakdown of key information (for example through FAQs or video messages) are crucial to ‘informed’ consent.

<!--Chapter 4-->

* All groups emphasised **fairness** as a key ethical principle, but the specifics of how fairness was understood differed between groups.
* Ensuring sufficient understanding of the trustworthy assurance methodology proved to be challenging in the time available. This was the case even with the participants who attended two workshops, where the first included preliminary material on the methodology.
  * Limits relevance of methodology to specific groups (e.g. regulators and developers). But does not preclude communicative potential.
  * Participants expressed positive sentiment towards the trustworthy assurance, noting its perceived value for processes such as transparent auditing, assessment, or procurement.
  * Producing assurance cases was a challenging exercise for many, but there were no signs that these barriers could not be addressed with additional user guidance and familiarity.
* Nearly all of the ethical issues raised can be captured by the SAFE-D principles and their core attributes. However, broader goals such as respecting human-rights and ensuring clinical efficacy should also be considered alongside the explicit ethical properties.
* Readiness, skills, and training should be prioritised both within organisations (e.g. how to implement ethical considerations into the project lifecycle) and across organisations (e.g. how to develop and adopt best practices). In addition, common capacity building should be supported by regulators and industry representatives (e.g. shared risk mapping, regulatory gap analysis, and horizon scanning activities to help create and maintain a common pool of expertise).[^commoncapacity]

#### Distrust as a barrier to access and use

* Organisations should consider both the *trustworthiness* of their products and services, but also the reasons why users may *trust or distrust* them.

#### Accountability through engagement

* Accountability should be built into all stages of the project lifecycle, and requires both stakeholder engagement and also diversity within the project team (especially neurodiversity).
* Where there is a risk of harm to users, organisations should be transparent about how these risks were identified (e.g. who was involved in the risk assessment), how they were mitigated, and what mechanisms for redress are available to impacted individuals.

#### Explainability as a pre-requisite for informed choice

* Information that is necessary to and supportive of informed choice should not be hidden within obscure privacy policies; it should be made accessible to users as explanations of how a system was designed, developed, and deployed.
* In doing so, organisations should be clear about how they define and operationalise key terms, such as 'mental health' or 'well-being' and how their understanding of the terms may have impacted the design, development, and evaluation of a service.

#### Fairness: reducing digital exclusion, bias and discrimination, and promoting social justice

<!--Chapter 5-->