### Possible Key Messages and Findings

<!-- Add suggestions here -->

<!--Chapter 3-->

\-        University teams must reflect on duty of care as a legal and ethical goal

\-        Policymakers and government departments must provide clarify on the relative responsibilities of the NHS and university teams to procure digital mental health technologies

\-        Greater attention must also be paid within universities to assigning responsibility for digital mental health technology procurement

\-        Meaningful student involvement is needed from the outset so student groups can contribute to establishing the overarching goals of student mental health decisions

\-        Universities must work together to leverage collective influence on developers such that developers provide them with more detailed information on the ethical implications of new technologies. Networks such as AMOSSHE, the UK’s Student Services Organisation, can play an important role in stepping forward to provide evidence-based guidance on these topics.

⁃       In an environment where resources are constrained, careful consideration is needed over whether the decision to procure a technology is justified. Where resources are limited, justification of expenditure must go beyond claims that digital services do not replace in-person support to make transparent where funds come from and why the benefits of a digital service are seen to outweigh other options.

⁃       Greater integration with research departments is needed to ensure evidence is available on who is best served by specific mental health services. Universities can draw on their own research resources in order to take a deeper look at who is and is not benefiting from digital interventions

⁃       Resource allocation within student services should take account of issues such as digital poverty, especially in light of the rise in remote learning following the pandemic.

⁃       A balance must be struck between empowering students to make their own choices without placing the burden of responsibility for mental health on them.

\-        To ensure students are aware of the services available, communications should be delivered by as many stakeholders as possible to include academic staff, student unions and student societies. University mental health teams should be careful to communicate honestly with students about both benefits and risks of technologies, including transparency communications about efficacy and data sharing.

\-        While in-depth and legally binding privacy policies are essential, an accessible breakdown of key information (for example through FAQs or video messages) are crucial to ‘informed’ consent.

<!--Chapter 4-->

* All groups emphasised **fairness** as a key ethical principle, but the specifics of how fairness was understood differed between groups.
* Ensuring sufficient understanding of the trustworthy assurance methodology proved to be challenging in the time available. This was the case even with the participants who attended two workshops, where the first included preliminary material on the methodology.
  * Limits relevance of methodology to specific groups (e.g. regulators and developers). But does not preclude communicative potential.
  * Participants expressed positive sentiment towards the trustworthy assurance, noting its perceived value for processes such as transparent auditing, assessment, or procurement.
  * Producing assurance cases was a challenging exercise for many, but there were no signs that these barriers could not be addressed with additional user guidance and familiarity.
* Nearly all of the ethical issues raised can be captured by the SAFE-D principles and their core attributes. However, broader goals such as respecting human-rights and ensuring clinical efficacy should also be considered alongside the explicit ethical properties.
* Readiness, skills, and training should be prioritised both within organisations (e.g. how to implement ethical considerations into the project lifecycle) and across organisations (e.g. how to develop and adopt best practices). In addition, common capacity building should be supported by regulators and industry representatives (e.g. shared risk mapping, regulatory gap analysis, and horizon scanning activities to help create and maintain a common pool of expertise).[^commoncapacity]

#### Distrust as a barrier to access and use

* Organisations should consider both the *trustworthiness* of their products and services, but also the reasons why users may *trust or distrust* them.

#### Accountability through engagement

* Accountability should be built into all stages of the project lifecycle, and requires both stakeholder engagement and also diversity within the project team (especially neurodiversity).
* Where there is a risk of harm to users, organisations should be transparent about how these risks were identified (e.g. who was involved in the risk assessment), how they were mitigated, and what mechanisms for redress are available to impacted individuals.

#### Explainability as a pre-requisite for informed choice

* Information that is necessary to and supportive of informed choice should not be hidden within obscure privacy policies; it should be made accessible to users as explanations of how a system was designed, developed, and deployed.
* In doing so, organisations should be clear about how they define and operationalise key terms, such as 'mental health' or 'well-being' and how their understanding of the terms may have impacted the design, development, and evaluation of a service.

#### Fairness: reducing digital exclusion, bias and discrimination, and promoting social justice

<!--Chapter 5-->